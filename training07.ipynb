{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b541a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, csv\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import LSTM, Dense, Dropout, Input, concatenate, Flatten, Reshape,MaxPooling2D, Conv2D, TimeDistributed\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import tensorflow.keras.backend as K\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "4e606a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DayAhead</th>\n",
       "      <th>Spot</th>\n",
       "      <th>REBAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.83200</td>\n",
       "      <td>3.688</td>\n",
       "      <td>-4.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.37575</td>\n",
       "      <td>4.245</td>\n",
       "      <td>-13.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.91950</td>\n",
       "      <td>3.161</td>\n",
       "      <td>0.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.46325</td>\n",
       "      <td>1.664</td>\n",
       "      <td>3.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00700</td>\n",
       "      <td>3.110</td>\n",
       "      <td>-6.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>3.77625</td>\n",
       "      <td>3.342</td>\n",
       "      <td>4.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>3.73900</td>\n",
       "      <td>4.425</td>\n",
       "      <td>8.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>3.70175</td>\n",
       "      <td>2.473</td>\n",
       "      <td>6.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>3.66450</td>\n",
       "      <td>3.241</td>\n",
       "      <td>11.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>3.62725</td>\n",
       "      <td>3.271</td>\n",
       "      <td>16.040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DayAhead   Spot   REBAP\n",
       "0       2.83200  3.688  -4.566\n",
       "1       2.37575  4.245 -13.964\n",
       "2       1.91950  3.161   0.345\n",
       "3       1.46325  1.664   3.048\n",
       "4       1.00700  3.110  -6.679\n",
       "...         ...    ...     ...\n",
       "35035   3.77625  3.342   4.856\n",
       "35036   3.73900  4.425   8.561\n",
       "35037   3.70175  2.473   6.076\n",
       "35038   3.66450  3.241  11.797\n",
       "35039   3.62725  3.271  16.040\n",
       "\n",
       "[35040 rows x 3 columns]"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load powerprice data and format it\n",
    "df_powerprice = pd.read_csv(\"data/PowerPrice.csv\")\n",
    "df_powerprice[\"Time\"] = pd.to_datetime(df_powerprice[\"Time\"], infer_datetime_format=True)\n",
    "df_powerprice = df_powerprice.drop(columns=[\"Time\"])\n",
    "df_powerprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "26b7f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spatial data and format it\n",
    "datasets = []\n",
    "for filename in os.listdir(\"data/Spatial\"):\n",
    "    if filename.endswith(\".pickle\"):\n",
    "        with open(os.path.join(\"data/Spatial\", filename), \"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "            if data.shape == (100, 35040):\n",
    "                datasets.append(data)\n",
    "            else:\n",
    "                print(f\"Skipping {filename}: unexpected shape {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "863e02aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 100, 35040)"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list of arrays to a 3D array\n",
    "spatial_data = np.stack(datasets, axis=0)\n",
    "\n",
    "spatial_data = spatial_data.reshape((spatial_data.shape[0], spatial_data.shape[1], spatial_data.shape[2]))\n",
    "\n",
    "# transpose the second and third dimensions to get shape (13, 35040, 100)\n",
    "spatial_data = spatial_data.transpose((0, 1, 2))\n",
    "\n",
    "spatial_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "d637fa40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30)"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load mask and reshape to match desired output shape\n",
    "mask = pd.read_csv(\"germany/mask.csv\", header=None).values\n",
    "#mask = mask_df.values.reshape((40, 40, 1))\n",
    "\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "d9b3f45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 100, 35040)"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "7ecc254a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_all = np.zeros((35040, 30, 30, 13))\n",
    "for j in range(spatial_data.shape[2]):\n",
    "    for i in range(spatial_data.shape[0]):\n",
    "        image = np.zeros((30, 30))\n",
    "        for s in range(spatial_data.shape[1]):\n",
    "            image[mask == s] = spatial_data[i,s,j]\n",
    "        #print(i)\n",
    "        image_all[j, :, :, i] = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "b671f36e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_all[35030,:,:,4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "0eaa7de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35040, 30, 30, 13)"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6d28bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c1d337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f037f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1745ea1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67e2c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "bb9abcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_2 = df_powerprice[\"DayAhead\"].values.reshape((-1, 4))\n",
    "#input_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "99932a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35040, 1)"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = df_powerprice[\"Spot\"].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "output = scaler.fit_transform(output.reshape(-1, 1))\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a207fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6dbc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "306b8808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(df, df2, window_size, look_ahead):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window_size - look_ahead + 1):\n",
    "        row = df[i:i+window_size, :, :, :]\n",
    "        X.append(row)\n",
    "        label = df2[i+window_size+look_ahead-1]\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "967cbf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (35036, 4, 30, 30, 13), y shape: (35036, 1)\n"
     ]
    }
   ],
   "source": [
    "window_size = 4\n",
    "look_ahead = 1\n",
    "X, y = split_datasets(image_all, output, window_size=window_size, look_ahead=look_ahead)\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b0c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "730b23b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled X shape: (35036, 4, 30, 30, 13)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the input array to a 2D array\n",
    "input_2d = X.reshape(-1, X.shape[-1])\n",
    "\n",
    "# Scale the array using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "input_scaled = scaler.fit_transform(input_2d)\n",
    "\n",
    "# Reshape the scaled array back to the original shape\n",
    "X = input_scaled.reshape(X.shape)\n",
    "\n",
    "print(\"Scaled X shape:\", X_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ed196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a9cf0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "88d4d6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (22422, 4, 30, 30, 13)\n",
      "y_train shape: (22422, 1)\n",
      "X_val shape: (5606, 4, 30, 30, 13)\n",
      "y_val shape: (5606, 1)\n",
      "X_test shape: (7008, 4, 30, 30, 13)\n",
      "y_test shape: (7008, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda41ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "5dc4bd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4, 30, 30, 13)]   0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 4, 28, 28, 16)    1888      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 4, 14, 14, 16)    0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 4, 12, 12, 32)    4640      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 4, 6, 6, 32)      0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 1152)           0         \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 4, 10)            11530     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " lstm1_1 (LSTM)              (None, 1)                 48        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,106\n",
      "Trainable params: 18,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "time_steps = 4\n",
    "width = 30\n",
    "height = 30\n",
    "channel = 13\n",
    "\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=(time_steps, width, height, channel))\n",
    "\n",
    "# Define the convolutional layers\n",
    "cnn1 = Conv2D(filters=16, kernel_size=(3, 3), activation='relu')\n",
    "cnn2 = MaxPooling2D(pool_size=(2, 2))\n",
    "cnn3 = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')\n",
    "cnn4 = MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "# Apply TimeDistributed to the convolutional layers\n",
    "td_cnn1 = TimeDistributed(cnn1)(input_layer)\n",
    "td_cnn2 = TimeDistributed(cnn2)(td_cnn1)\n",
    "td_cnn3 = TimeDistributed(cnn3)(td_cnn2)\n",
    "td_cnn4 = TimeDistributed(cnn4)(td_cnn3)\n",
    "\n",
    "# Reshape the output of the convolutional layers\n",
    "reshaped = Reshape((-1, 6*6*32))(td_cnn4)\n",
    "\n",
    "# Apply TimeDistributed Dense layer\n",
    "td_fcnn = TimeDistributed(Dense(10, activation='relu', name='output'))(reshaped)\n",
    "\n",
    "# Apply LSTM layer\n",
    "lstm_output = LSTM(1, name='lstm1_1')(td_fcnn)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=lstm_output)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c9fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "360437be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with an appropriate optimizer and loss function\n",
    "\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "ede87ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks for early stopping and checkpoint saving\n",
    "es = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "dc55f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = ModelCheckpoint(filepath=\"training/cnn-lstm/\", \n",
    "                      save_best_only=True,\n",
    "                      monitor='val_loss', \n",
    "                      mode='min', \n",
    "                      save_weights_only=False, \n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271981ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "698/701 [============================>.] - ETA: 0s - loss: 0.0022 - root_mean_squared_error: 0.0470\n",
      "Epoch 1: val_loss improved from inf to 0.00041, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 24s 31ms/step - loss: 0.0022 - root_mean_squared_error: 0.0470 - val_loss: 4.0611e-04 - val_root_mean_squared_error: 0.0202\n",
      "Epoch 2/1000\n",
      "696/701 [============================>.] - ETA: 0s - loss: 3.4371e-04 - root_mean_squared_error: 0.0185\n",
      "Epoch 2: val_loss improved from 0.00041 to 0.00036, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 17s 24ms/step - loss: 3.4358e-04 - root_mean_squared_error: 0.0185 - val_loss: 3.6083e-04 - val_root_mean_squared_error: 0.0190\n",
      "Epoch 3/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 2.9244e-04 - root_mean_squared_error: 0.0171\n",
      "Epoch 3: val_loss improved from 0.00036 to 0.00030, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 15s 22ms/step - loss: 2.9205e-04 - root_mean_squared_error: 0.0171 - val_loss: 2.9775e-04 - val_root_mean_squared_error: 0.0173\n",
      "Epoch 4/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 2.7135e-04 - root_mean_squared_error: 0.0165\n",
      "Epoch 4: val_loss improved from 0.00030 to 0.00028, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 15s 21ms/step - loss: 2.7102e-04 - root_mean_squared_error: 0.0165 - val_loss: 2.7590e-04 - val_root_mean_squared_error: 0.0166\n",
      "Epoch 5/1000\n",
      "701/701 [==============================] - ETA: 0s - loss: 2.5392e-04 - root_mean_squared_error: 0.0159\n",
      "Epoch 5: val_loss improved from 0.00028 to 0.00027, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 15s 22ms/step - loss: 2.5392e-04 - root_mean_squared_error: 0.0159 - val_loss: 2.7490e-04 - val_root_mean_squared_error: 0.0166\n",
      "Epoch 6/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 2.4619e-04 - root_mean_squared_error: 0.0157\n",
      "Epoch 6: val_loss improved from 0.00027 to 0.00027, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 15s 21ms/step - loss: 2.4598e-04 - root_mean_squared_error: 0.0157 - val_loss: 2.6556e-04 - val_root_mean_squared_error: 0.0163\n",
      "Epoch 7/1000\n",
      "698/701 [============================>.] - ETA: 0s - loss: 2.3512e-04 - root_mean_squared_error: 0.0153\n",
      "Epoch 7: val_loss improved from 0.00027 to 0.00024, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 20ms/step - loss: 2.3494e-04 - root_mean_squared_error: 0.0153 - val_loss: 2.4494e-04 - val_root_mean_squared_error: 0.0157\n",
      "Epoch 8/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 2.3376e-04 - root_mean_squared_error: 0.0153\n",
      "Epoch 8: val_loss improved from 0.00024 to 0.00024, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 20ms/step - loss: 2.3335e-04 - root_mean_squared_error: 0.0153 - val_loss: 2.4170e-04 - val_root_mean_squared_error: 0.0155\n",
      "Epoch 9/1000\n",
      "698/701 [============================>.] - ETA: 0s - loss: 2.2726e-04 - root_mean_squared_error: 0.0151\n",
      "Epoch 9: val_loss improved from 0.00024 to 0.00024, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 21ms/step - loss: 2.2714e-04 - root_mean_squared_error: 0.0151 - val_loss: 2.3501e-04 - val_root_mean_squared_error: 0.0153\n",
      "Epoch 10/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 2.2312e-04 - root_mean_squared_error: 0.0149\n",
      "Epoch 10: val_loss did not improve from 0.00024\n",
      "701/701 [==============================] - 8s 12ms/step - loss: 2.2268e-04 - root_mean_squared_error: 0.0149 - val_loss: 2.5460e-04 - val_root_mean_squared_error: 0.0160\n",
      "Epoch 11/1000\n",
      "701/701 [==============================] - ETA: 0s - loss: 2.2068e-04 - root_mean_squared_error: 0.0149\n",
      "Epoch 11: val_loss improved from 0.00024 to 0.00023, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 21ms/step - loss: 2.2068e-04 - root_mean_squared_error: 0.0149 - val_loss: 2.2726e-04 - val_root_mean_squared_error: 0.0151\n",
      "Epoch 12/1000\n",
      "701/701 [==============================] - ETA: 0s - loss: 2.1353e-04 - root_mean_squared_error: 0.0146\n",
      "Epoch 12: val_loss did not improve from 0.00023\n",
      "701/701 [==============================] - 9s 13ms/step - loss: 2.1353e-04 - root_mean_squared_error: 0.0146 - val_loss: 2.4374e-04 - val_root_mean_squared_error: 0.0156\n",
      "Epoch 13/1000\n",
      "700/701 [============================>.] - ETA: 0s - loss: 2.0587e-04 - root_mean_squared_error: 0.0143\n",
      "Epoch 13: val_loss improved from 0.00023 to 0.00023, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 21ms/step - loss: 2.0955e-04 - root_mean_squared_error: 0.0145 - val_loss: 2.2710e-04 - val_root_mean_squared_error: 0.0151\n",
      "Epoch 14/1000\n",
      "695/701 [============================>.] - ETA: 0s - loss: 2.0930e-04 - root_mean_squared_error: 0.0145\n",
      "Epoch 14: val_loss improved from 0.00023 to 0.00022, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 20ms/step - loss: 2.0849e-04 - root_mean_squared_error: 0.0144 - val_loss: 2.2256e-04 - val_root_mean_squared_error: 0.0149\n",
      "Epoch 15/1000\n",
      "696/701 [============================>.] - ETA: 0s - loss: 2.0507e-04 - root_mean_squared_error: 0.0143\n",
      "Epoch 15: val_loss improved from 0.00022 to 0.00021, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 20ms/step - loss: 2.0530e-04 - root_mean_squared_error: 0.0143 - val_loss: 2.1437e-04 - val_root_mean_squared_error: 0.0146\n",
      "Epoch 16/1000\n",
      "698/701 [============================>.] - ETA: 0s - loss: 2.0159e-04 - root_mean_squared_error: 0.0142\n",
      "Epoch 16: val_loss improved from 0.00021 to 0.00021, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 17s 24ms/step - loss: 2.0111e-04 - root_mean_squared_error: 0.0142 - val_loss: 2.1224e-04 - val_root_mean_squared_error: 0.0146\n",
      "Epoch 17/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 1.9910e-04 - root_mean_squared_error: 0.0141\n",
      "Epoch 17: val_loss did not improve from 0.00021\n",
      "701/701 [==============================] - 9s 12ms/step - loss: 1.9879e-04 - root_mean_squared_error: 0.0141 - val_loss: 2.1975e-04 - val_root_mean_squared_error: 0.0148\n",
      "Epoch 18/1000\n",
      "698/701 [============================>.] - ETA: 0s - loss: 1.9572e-04 - root_mean_squared_error: 0.0140\n",
      "Epoch 18: val_loss improved from 0.00021 to 0.00020, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 15s 21ms/step - loss: 1.9556e-04 - root_mean_squared_error: 0.0140 - val_loss: 2.0300e-04 - val_root_mean_squared_error: 0.0142\n",
      "Epoch 19/1000\n",
      "700/701 [============================>.] - ETA: 0s - loss: 1.9483e-04 - root_mean_squared_error: 0.0140\n",
      "Epoch 19: val_loss did not improve from 0.00020\n",
      "701/701 [==============================] - 8s 12ms/step - loss: 1.9491e-04 - root_mean_squared_error: 0.0140 - val_loss: 2.1311e-04 - val_root_mean_squared_error: 0.0146\n",
      "Epoch 20/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 1.9263e-04 - root_mean_squared_error: 0.0139\n",
      "Epoch 20: val_loss did not improve from 0.00020\n",
      "701/701 [==============================] - 9s 13ms/step - loss: 1.9240e-04 - root_mean_squared_error: 0.0139 - val_loss: 2.1215e-04 - val_root_mean_squared_error: 0.0146\n",
      "Epoch 21/1000\n",
      "698/701 [============================>.] - ETA: 0s - loss: 1.8787e-04 - root_mean_squared_error: 0.0137\n",
      "Epoch 21: val_loss improved from 0.00020 to 0.00020, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 16s 22ms/step - loss: 1.8759e-04 - root_mean_squared_error: 0.0137 - val_loss: 1.9756e-04 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 22/1000\n",
      "696/701 [============================>.] - ETA: 0s - loss: 1.8945e-04 - root_mean_squared_error: 0.0138\n",
      "Epoch 22: val_loss improved from 0.00020 to 0.00020, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 20ms/step - loss: 1.8898e-04 - root_mean_squared_error: 0.0137 - val_loss: 1.9549e-04 - val_root_mean_squared_error: 0.0140\n",
      "Epoch 23/1000\n",
      "701/701 [==============================] - ETA: 0s - loss: 1.8577e-04 - root_mean_squared_error: 0.0136\n",
      "Epoch 23: val_loss did not improve from 0.00020\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.8577e-04 - root_mean_squared_error: 0.0136 - val_loss: 1.9737e-04 - val_root_mean_squared_error: 0.0140\n",
      "Epoch 24/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 1.8383e-04 - root_mean_squared_error: 0.0136\n",
      "Epoch 24: val_loss improved from 0.00020 to 0.00019, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 21ms/step - loss: 1.8353e-04 - root_mean_squared_error: 0.0135 - val_loss: 1.9010e-04 - val_root_mean_squared_error: 0.0138\n",
      "Epoch 25/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 1.8080e-04 - root_mean_squared_error: 0.0134\n",
      "Epoch 25: val_loss improved from 0.00019 to 0.00019, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 15s 21ms/step - loss: 1.8088e-04 - root_mean_squared_error: 0.0134 - val_loss: 1.8813e-04 - val_root_mean_squared_error: 0.0137\n",
      "Epoch 26/1000\n",
      "701/701 [==============================] - ETA: 0s - loss: 1.7818e-04 - root_mean_squared_error: 0.0133\n",
      "Epoch 26: val_loss did not improve from 0.00019\n",
      "701/701 [==============================] - 9s 13ms/step - loss: 1.7818e-04 - root_mean_squared_error: 0.0133 - val_loss: 1.8949e-04 - val_root_mean_squared_error: 0.0138\n",
      "Epoch 27/1000\n",
      "695/701 [============================>.] - ETA: 0s - loss: 1.7467e-04 - root_mean_squared_error: 0.0132\n",
      "Epoch 27: val_loss did not improve from 0.00019\n",
      "701/701 [==============================] - 8s 12ms/step - loss: 1.7417e-04 - root_mean_squared_error: 0.0132 - val_loss: 1.9118e-04 - val_root_mean_squared_error: 0.0138\n",
      "Epoch 28/1000\n",
      "700/701 [============================>.] - ETA: 0s - loss: 1.7396e-04 - root_mean_squared_error: 0.0132\n",
      "Epoch 28: val_loss did not improve from 0.00019\n",
      "701/701 [==============================] - 8s 12ms/step - loss: 1.7382e-04 - root_mean_squared_error: 0.0132 - val_loss: 1.9939e-04 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 29/1000\n",
      "700/701 [============================>.] - ETA: 0s - loss: 1.7540e-04 - root_mean_squared_error: 0.0132\n",
      "Epoch 29: val_loss did not improve from 0.00019\n",
      "701/701 [==============================] - 8s 12ms/step - loss: 1.7530e-04 - root_mean_squared_error: 0.0132 - val_loss: 1.9193e-04 - val_root_mean_squared_error: 0.0139\n",
      "Epoch 30/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 1.7058e-04 - root_mean_squared_error: 0.0131\n",
      "Epoch 30: val_loss improved from 0.00019 to 0.00018, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 15s 21ms/step - loss: 1.7037e-04 - root_mean_squared_error: 0.0131 - val_loss: 1.8038e-04 - val_root_mean_squared_error: 0.0134\n",
      "Epoch 31/1000\n",
      "700/701 [============================>.] - ETA: 0s - loss: 1.6877e-04 - root_mean_squared_error: 0.0130\n",
      "Epoch 31: val_loss did not improve from 0.00018\n",
      "701/701 [==============================] - 8s 12ms/step - loss: 1.6867e-04 - root_mean_squared_error: 0.0130 - val_loss: 1.9610e-04 - val_root_mean_squared_error: 0.0140\n",
      "Epoch 32/1000\n",
      "700/701 [============================>.] - ETA: 0s - loss: 1.6786e-04 - root_mean_squared_error: 0.0130\n",
      "Epoch 32: val_loss improved from 0.00018 to 0.00018, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 15s 21ms/step - loss: 1.6776e-04 - root_mean_squared_error: 0.0130 - val_loss: 1.7864e-04 - val_root_mean_squared_error: 0.0134\n",
      "Epoch 33/1000\n",
      "696/701 [============================>.] - ETA: 0s - loss: 1.6503e-04 - root_mean_squared_error: 0.0128\n",
      "Epoch 33: val_loss improved from 0.00018 to 0.00017, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 20ms/step - loss: 1.6482e-04 - root_mean_squared_error: 0.0128 - val_loss: 1.7301e-04 - val_root_mean_squared_error: 0.0132\n",
      "Epoch 34/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 1.6445e-04 - root_mean_squared_error: 0.0128\n",
      "Epoch 34: val_loss did not improve from 0.00017\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.6422e-04 - root_mean_squared_error: 0.0128 - val_loss: 1.9106e-04 - val_root_mean_squared_error: 0.0138\n",
      "Epoch 35/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 1.6306e-04 - root_mean_squared_error: 0.0128\n",
      "Epoch 35: val_loss did not improve from 0.00017\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.6298e-04 - root_mean_squared_error: 0.0128 - val_loss: 2.0275e-04 - val_root_mean_squared_error: 0.0142\n",
      "Epoch 36/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 1.6301e-04 - root_mean_squared_error: 0.0128\n",
      "Epoch 36: val_loss improved from 0.00017 to 0.00016, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 15s 21ms/step - loss: 1.6271e-04 - root_mean_squared_error: 0.0128 - val_loss: 1.6402e-04 - val_root_mean_squared_error: 0.0128\n",
      "Epoch 37/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 1.6092e-04 - root_mean_squared_error: 0.0127\n",
      "Epoch 37: val_loss did not improve from 0.00016\n",
      "701/701 [==============================] - 9s 12ms/step - loss: 1.6087e-04 - root_mean_squared_error: 0.0127 - val_loss: 1.6855e-04 - val_root_mean_squared_error: 0.0130\n",
      "Epoch 38/1000\n",
      "696/701 [============================>.] - ETA: 0s - loss: 1.6031e-04 - root_mean_squared_error: 0.0127\n",
      "Epoch 38: val_loss did not improve from 0.00016\n",
      "701/701 [==============================] - 9s 12ms/step - loss: 1.6002e-04 - root_mean_squared_error: 0.0126 - val_loss: 1.6554e-04 - val_root_mean_squared_error: 0.0129\n",
      "Epoch 39/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 1.5881e-04 - root_mean_squared_error: 0.0126\n",
      "Epoch 39: val_loss improved from 0.00016 to 0.00016, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 16s 23ms/step - loss: 1.5871e-04 - root_mean_squared_error: 0.0126 - val_loss: 1.6324e-04 - val_root_mean_squared_error: 0.0128\n",
      "Epoch 40/1000\n",
      "701/701 [==============================] - ETA: 0s - loss: 1.5844e-04 - root_mean_squared_error: 0.0126\n",
      "Epoch 40: val_loss did not improve from 0.00016\n",
      "701/701 [==============================] - 9s 13ms/step - loss: 1.5844e-04 - root_mean_squared_error: 0.0126 - val_loss: 1.8358e-04 - val_root_mean_squared_error: 0.0135\n",
      "Epoch 41/1000\n",
      "695/701 [============================>.] - ETA: 0s - loss: 1.5540e-04 - root_mean_squared_error: 0.0125\n",
      "Epoch 41: val_loss did not improve from 0.00016\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.5484e-04 - root_mean_squared_error: 0.0124 - val_loss: 1.6477e-04 - val_root_mean_squared_error: 0.0128\n",
      "Epoch 42/1000\n",
      "701/701 [==============================] - ETA: 0s - loss: 1.5376e-04 - root_mean_squared_error: 0.0124\n",
      "Epoch 42: val_loss did not improve from 0.00016\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.5376e-04 - root_mean_squared_error: 0.0124 - val_loss: 1.7019e-04 - val_root_mean_squared_error: 0.0130\n",
      "Epoch 43/1000\n",
      "698/701 [============================>.] - ETA: 0s - loss: 1.5298e-04 - root_mean_squared_error: 0.0124\n",
      "Epoch 43: val_loss improved from 0.00016 to 0.00016, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 21ms/step - loss: 1.5291e-04 - root_mean_squared_error: 0.0124 - val_loss: 1.5724e-04 - val_root_mean_squared_error: 0.0125\n",
      "Epoch 44/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 1.5561e-04 - root_mean_squared_error: 0.0125\n",
      "Epoch 44: val_loss did not improve from 0.00016\n",
      "701/701 [==============================] - 9s 13ms/step - loss: 1.5555e-04 - root_mean_squared_error: 0.0125 - val_loss: 1.6589e-04 - val_root_mean_squared_error: 0.0129\n",
      "Epoch 45/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 1.5030e-04 - root_mean_squared_error: 0.0123\n",
      "Epoch 45: val_loss did not improve from 0.00016\n",
      "701/701 [==============================] - 8s 12ms/step - loss: 1.5017e-04 - root_mean_squared_error: 0.0123 - val_loss: 1.5781e-04 - val_root_mean_squared_error: 0.0126\n",
      "Epoch 46/1000\n",
      "700/701 [============================>.] - ETA: 0s - loss: 1.5001e-04 - root_mean_squared_error: 0.0122\n",
      "Epoch 46: val_loss did not improve from 0.00016\n",
      "701/701 [==============================] - 9s 12ms/step - loss: 1.4996e-04 - root_mean_squared_error: 0.0122 - val_loss: 1.5903e-04 - val_root_mean_squared_error: 0.0126\n",
      "Epoch 47/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 1.4934e-04 - root_mean_squared_error: 0.0122\n",
      "Epoch 47: val_loss did not improve from 0.00016\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.4926e-04 - root_mean_squared_error: 0.0122 - val_loss: 1.5757e-04 - val_root_mean_squared_error: 0.0126\n",
      "Epoch 48/1000\n",
      "696/701 [============================>.] - ETA: 0s - loss: 1.4834e-04 - root_mean_squared_error: 0.0122\n",
      "Epoch 48: val_loss did not improve from 0.00016\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.4813e-04 - root_mean_squared_error: 0.0122 - val_loss: 1.7284e-04 - val_root_mean_squared_error: 0.0131\n",
      "Epoch 49/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 1.4776e-04 - root_mean_squared_error: 0.0122\n",
      "Epoch 49: val_loss improved from 0.00016 to 0.00015, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 20ms/step - loss: 1.4761e-04 - root_mean_squared_error: 0.0121 - val_loss: 1.5407e-04 - val_root_mean_squared_error: 0.0124\n",
      "Epoch 50/1000\n",
      "700/701 [============================>.] - ETA: 0s - loss: 1.4566e-04 - root_mean_squared_error: 0.0121\n",
      "Epoch 50: val_loss improved from 0.00015 to 0.00015, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 15s 21ms/step - loss: 1.4575e-04 - root_mean_squared_error: 0.0121 - val_loss: 1.5001e-04 - val_root_mean_squared_error: 0.0122\n",
      "Epoch 51/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 1.4442e-04 - root_mean_squared_error: 0.0120\n",
      "Epoch 51: val_loss did not improve from 0.00015\n",
      "701/701 [==============================] - 9s 12ms/step - loss: 1.4454e-04 - root_mean_squared_error: 0.0120 - val_loss: 1.6204e-04 - val_root_mean_squared_error: 0.0127\n",
      "Epoch 52/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 1.4575e-04 - root_mean_squared_error: 0.0121\n",
      "Epoch 52: val_loss improved from 0.00015 to 0.00015, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 20ms/step - loss: 1.4589e-04 - root_mean_squared_error: 0.0121 - val_loss: 1.4742e-04 - val_root_mean_squared_error: 0.0121\n",
      "Epoch 53/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 1.4281e-04 - root_mean_squared_error: 0.0120\n",
      "Epoch 53: val_loss did not improve from 0.00015\n",
      "701/701 [==============================] - 7s 11ms/step - loss: 1.4251e-04 - root_mean_squared_error: 0.0119 - val_loss: 1.5140e-04 - val_root_mean_squared_error: 0.0123\n",
      "Epoch 54/1000\n",
      "695/701 [============================>.] - ETA: 0s - loss: 1.4304e-04 - root_mean_squared_error: 0.0120\n",
      "Epoch 54: val_loss did not improve from 0.00015\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.4273e-04 - root_mean_squared_error: 0.0119 - val_loss: 1.6018e-04 - val_root_mean_squared_error: 0.0127\n",
      "Epoch 55/1000\n",
      "700/701 [============================>.] - ETA: 0s - loss: 1.4174e-04 - root_mean_squared_error: 0.0119\n",
      "Epoch 55: val_loss did not improve from 0.00015\n",
      "701/701 [==============================] - 8s 12ms/step - loss: 1.4167e-04 - root_mean_squared_error: 0.0119 - val_loss: 1.6904e-04 - val_root_mean_squared_error: 0.0130\n",
      "Epoch 56/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 1.4104e-04 - root_mean_squared_error: 0.0119\n",
      "Epoch 56: val_loss did not improve from 0.00015\n",
      "701/701 [==============================] - 8s 12ms/step - loss: 1.4086e-04 - root_mean_squared_error: 0.0119 - val_loss: 1.4996e-04 - val_root_mean_squared_error: 0.0122\n",
      "Epoch 57/1000\n",
      "696/701 [============================>.] - ETA: 0s - loss: 1.4236e-04 - root_mean_squared_error: 0.0119\n",
      "Epoch 57: val_loss did not improve from 0.00015\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.4230e-04 - root_mean_squared_error: 0.0119 - val_loss: 1.6400e-04 - val_root_mean_squared_error: 0.0128\n",
      "Epoch 58/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 1.3932e-04 - root_mean_squared_error: 0.0118\n",
      "Epoch 58: val_loss did not improve from 0.00015\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.3916e-04 - root_mean_squared_error: 0.0118 - val_loss: 1.4808e-04 - val_root_mean_squared_error: 0.0122\n",
      "Epoch 59/1000\n",
      "698/701 [============================>.] - ETA: 0s - loss: 1.3729e-04 - root_mean_squared_error: 0.0117\n",
      "Epoch 59: val_loss did not improve from 0.00015\n",
      "701/701 [==============================] - 7s 11ms/step - loss: 1.3725e-04 - root_mean_squared_error: 0.0117 - val_loss: 1.4932e-04 - val_root_mean_squared_error: 0.0122\n",
      "Epoch 60/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 1.3727e-04 - root_mean_squared_error: 0.0117\n",
      "Epoch 60: val_loss did not improve from 0.00015\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.3716e-04 - root_mean_squared_error: 0.0117 - val_loss: 1.4752e-04 - val_root_mean_squared_error: 0.0121\n",
      "Epoch 61/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 1.3662e-04 - root_mean_squared_error: 0.0117\n",
      "Epoch 61: val_loss improved from 0.00015 to 0.00014, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 20ms/step - loss: 1.3645e-04 - root_mean_squared_error: 0.0117 - val_loss: 1.4457e-04 - val_root_mean_squared_error: 0.0120\n",
      "Epoch 62/1000\n",
      "695/701 [============================>.] - ETA: 0s - loss: 1.3639e-04 - root_mean_squared_error: 0.0117\n",
      "Epoch 62: val_loss improved from 0.00014 to 0.00014, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 15s 21ms/step - loss: 1.3591e-04 - root_mean_squared_error: 0.0117 - val_loss: 1.4278e-04 - val_root_mean_squared_error: 0.0119\n",
      "Epoch 63/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 1.3500e-04 - root_mean_squared_error: 0.0116\n",
      "Epoch 63: val_loss did not improve from 0.00014\n",
      "701/701 [==============================] - 8s 12ms/step - loss: 1.3491e-04 - root_mean_squared_error: 0.0116 - val_loss: 1.5092e-04 - val_root_mean_squared_error: 0.0123\n",
      "Epoch 64/1000\n",
      "700/701 [============================>.] - ETA: 0s - loss: 1.3565e-04 - root_mean_squared_error: 0.0116\n",
      "Epoch 64: val_loss improved from 0.00014 to 0.00014, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 20ms/step - loss: 1.3563e-04 - root_mean_squared_error: 0.0116 - val_loss: 1.4041e-04 - val_root_mean_squared_error: 0.0118\n",
      "Epoch 65/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 1.3311e-04 - root_mean_squared_error: 0.0115\n",
      "Epoch 65: val_loss did not improve from 0.00014\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.3311e-04 - root_mean_squared_error: 0.0115 - val_loss: 1.4818e-04 - val_root_mean_squared_error: 0.0122\n",
      "Epoch 66/1000\n",
      "701/701 [==============================] - ETA: 0s - loss: 1.3374e-04 - root_mean_squared_error: 0.0116\n",
      "Epoch 66: val_loss did not improve from 0.00014\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.3374e-04 - root_mean_squared_error: 0.0116 - val_loss: 1.4136e-04 - val_root_mean_squared_error: 0.0119\n",
      "Epoch 67/1000\n",
      "701/701 [==============================] - ETA: 0s - loss: 1.3348e-04 - root_mean_squared_error: 0.0116\n",
      "Epoch 67: val_loss improved from 0.00014 to 0.00014, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 14s 20ms/step - loss: 1.3348e-04 - root_mean_squared_error: 0.0116 - val_loss: 1.3872e-04 - val_root_mean_squared_error: 0.0118\n",
      "Epoch 68/1000\n",
      "701/701 [==============================] - ETA: 0s - loss: 1.3045e-04 - root_mean_squared_error: 0.0114\n",
      "Epoch 68: val_loss did not improve from 0.00014\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.3045e-04 - root_mean_squared_error: 0.0114 - val_loss: 1.3939e-04 - val_root_mean_squared_error: 0.0118\n",
      "Epoch 69/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 1.3149e-04 - root_mean_squared_error: 0.0115\n",
      "Epoch 69: val_loss did not improve from 0.00014\n",
      "701/701 [==============================] - 8s 12ms/step - loss: 1.3169e-04 - root_mean_squared_error: 0.0115 - val_loss: 1.5258e-04 - val_root_mean_squared_error: 0.0124\n",
      "Epoch 70/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 1.3070e-04 - root_mean_squared_error: 0.0114\n",
      "Epoch 70: val_loss did not improve from 0.00014\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.3059e-04 - root_mean_squared_error: 0.0114 - val_loss: 1.8173e-04 - val_root_mean_squared_error: 0.0135\n",
      "Epoch 71/1000\n",
      "700/701 [============================>.] - ETA: 0s - loss: 1.3117e-04 - root_mean_squared_error: 0.0115\n",
      "Epoch 71: val_loss did not improve from 0.00014\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.3113e-04 - root_mean_squared_error: 0.0115 - val_loss: 1.3977e-04 - val_root_mean_squared_error: 0.0118\n",
      "Epoch 72/1000\n",
      "701/701 [==============================] - ETA: 0s - loss: 1.3078e-04 - root_mean_squared_error: 0.0114\n",
      "Epoch 72: val_loss did not improve from 0.00014\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.3078e-04 - root_mean_squared_error: 0.0114 - val_loss: 1.4457e-04 - val_root_mean_squared_error: 0.0120\n",
      "Epoch 73/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 1.3027e-04 - root_mean_squared_error: 0.0114\n",
      "Epoch 73: val_loss improved from 0.00014 to 0.00013, saving model to training/cnn-lstm\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/cnn-lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 15s 21ms/step - loss: 1.3068e-04 - root_mean_squared_error: 0.0114 - val_loss: 1.3373e-04 - val_root_mean_squared_error: 0.0116\n",
      "Epoch 74/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 1.2810e-04 - root_mean_squared_error: 0.0113\n",
      "Epoch 74: val_loss did not improve from 0.00013\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.2807e-04 - root_mean_squared_error: 0.0113 - val_loss: 1.3554e-04 - val_root_mean_squared_error: 0.0116\n",
      "Epoch 75/1000\n",
      "699/701 [============================>.] - ETA: 0s - loss: 1.2473e-04 - root_mean_squared_error: 0.0112\n",
      "Epoch 75: val_loss did not improve from 0.00013\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 1.2874e-04 - root_mean_squared_error: 0.0113 - val_loss: 1.4520e-04 - val_root_mean_squared_error: 0.0121\n",
      "Epoch 76/1000\n",
      "700/701 [============================>.] - ETA: 0s - loss: 1.3127e-04 - root_mean_squared_error: 0.0115\n",
      "Epoch 76: val_loss did not improve from 0.00013\n",
      "701/701 [==============================] - 9s 13ms/step - loss: 1.3121e-04 - root_mean_squared_error: 0.0115 - val_loss: 1.3546e-04 - val_root_mean_squared_error: 0.0116\n",
      "Epoch 77/1000\n",
      "697/701 [============================>.] - ETA: 0s - loss: 1.2939e-04 - root_mean_squared_error: 0.0114\n",
      "Epoch 77: val_loss did not improve from 0.00013\n",
      "701/701 [==============================] - 9s 13ms/step - loss: 1.2912e-04 - root_mean_squared_error: 0.0114 - val_loss: 1.4219e-04 - val_root_mean_squared_error: 0.0119\n",
      "Epoch 78/1000\n",
      "696/701 [============================>.] - ETA: 0s - loss: 1.2490e-04 - root_mean_squared_error: 0.0112\n",
      "Epoch 78: val_loss did not improve from 0.00013\n",
      "701/701 [==============================] - 9s 13ms/step - loss: 1.2490e-04 - root_mean_squared_error: 0.0112 - val_loss: 1.3942e-04 - val_root_mean_squared_error: 0.0118\n",
      "Epoch 79/1000\n",
      "696/701 [============================>.] - ETA: 0s - loss: 1.2730e-04 - root_mean_squared_error: 0.0113\n",
      "Epoch 79: val_loss did not improve from 0.00013\n",
      "701/701 [==============================] - 9s 12ms/step - loss: 1.2714e-04 - root_mean_squared_error: 0.0113 - val_loss: 1.4515e-04 - val_root_mean_squared_error: 0.0120\n",
      "Epoch 80/1000\n",
      "696/701 [============================>.] - ETA: 0s - loss: 1.2470e-04 - root_mean_squared_error: 0.0112\n",
      "Epoch 80: val_loss did not improve from 0.00013\n",
      "701/701 [==============================] - 8s 12ms/step - loss: 1.2437e-04 - root_mean_squared_error: 0.0112 - val_loss: 1.3581e-04 - val_root_mean_squared_error: 0.0117\n",
      "Epoch 81/1000\n",
      "701/701 [==============================] - ETA: 0s - loss: 1.2490e-04 - root_mean_squared_error: 0.0112\n",
      "Epoch 81: val_loss did not improve from 0.00013\n",
      "701/701 [==============================] - 7s 11ms/step - loss: 1.2490e-04 - root_mean_squared_error: 0.0112 - val_loss: 1.3519e-04 - val_root_mean_squared_error: 0.0116\n",
      "Epoch 82/1000\n",
      "695/701 [============================>.] - ETA: 0s - loss: 1.2358e-04 - root_mean_squared_error: 0.0111\n",
      "Epoch 82: val_loss did not improve from 0.00013\n",
      "701/701 [==============================] - 8s 12ms/step - loss: 1.2421e-04 - root_mean_squared_error: 0.0111 - val_loss: 1.4504e-04 - val_root_mean_squared_error: 0.0120\n",
      "Epoch 83/1000\n",
      "137/701 [====>.........................] - ETA: 7s - loss: 1.1989e-04 - root_mean_squared_error: 0.0109"
     ]
    }
   ],
   "source": [
    "# Fit the model on the training data\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=1000, validation_data=(X_val, y_val), callbacks=[cp, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602bd9ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12016\\2529094509.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the training and validation loss\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['loss'][1:])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6407173b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b578c2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fab2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f088e22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62cdf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d383b650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869f6f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0169b6df",
   "metadata": {},
   "source": [
    "#### getting the result of (32, 6, 40, 40, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1e4f2301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (32, 6, 40, 40, 13)\n"
     ]
    }
   ],
   "source": [
    "image = image_slided[np.random.choice(image_slided.shape[0], 32, replace=False)] # just randomly picking the sample from 35035.\n",
    "\n",
    "image = image.reshape(32, -1, 40, 40, 13)\n",
    "\n",
    "print(f\"image shape: {image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ddadea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79569fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f236d43",
   "metadata": {},
   "source": [
    "#### getting the result of (32*6, 40, 40, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "939fc2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 40, 40, 13)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = image.reshape(-1, 40, 40, 13)\n",
    "\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b45f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f63c4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d30d0a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 10])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input = Input(shape=(40, 40, 13))\n",
    "conv_layer = Conv2D(32, kernel_size=(3,3), activation=\"relu\")(df_input)\n",
    "conv_layer = MaxPooling2D(pool_size=(2, 2))(conv_layer)\n",
    "conv_layer = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(conv_layer)\n",
    "conv_layer = MaxPooling2D(pool_size=(2, 2))(conv_layer)\n",
    "flatten_layer = Flatten()(conv_layer)\n",
    "fcnn_layer = Dense(64, activation=\"relu\")(flatten_layer)\n",
    "fcnn_layer = Dropout(0.2)(fcnn_layer)\n",
    "fcnn_layer = Dense(32, activation=\"relu\")(fcnn_layer)\n",
    "fcnn_layer = Dropout(0.2)(fcnn_layer)\n",
    "fcnn_output = Dense(10, activation=\"relu\")(fcnn_layer)\n",
    "\n",
    "fcnn_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9c76e16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 40, 40, 13)]      0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 38, 38, 32)        3776      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 19, 19, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 17, 17, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 8, 8, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                262208    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 286,890\n",
      "Trainable params: 286,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=df_input, outputs=fcnn_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "0bbcb674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with optimizer and loss function\n",
    "model.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeecd32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b7c75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a03cbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e38a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d5000d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5316076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094b3b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd9856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1da0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9673198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27886f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dfba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(32*6, 4, 4, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf9946",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c485ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "(32*6, 4*4*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054013ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "(32*6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9024692",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab0fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(32, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eae24ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef02546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b15a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1644ebf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969e8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7289e74e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb8b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8eef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d047ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
